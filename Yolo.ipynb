{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b730196e",
   "metadata": {},
   "source": [
    "# Building & Analysis of Facial Video Dataset from Youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f12f8d",
   "metadata": {},
   "source": [
    "### Load Dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "309e8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "import cv2\n",
    "import numpy as np \n",
    "import os\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffce478",
   "metadata": {},
   "source": [
    "### Load Yolo weights file and read the classes from 'coco.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "600721dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person\r\n",
      "bicycle\r\n",
      "car\r\n",
      "motorbike\r\n",
      "aeroplane\r\n",
      "bus\r\n",
      "train\r\n",
      "truck\r\n",
      "boat\r\n",
      "traffic light\r\n",
      "fire hydrant\r\n",
      "stop sign\r\n",
      "parking meter\r\n",
      "bench\r\n",
      "bird\r\n",
      "cat\r\n",
      "dog\r\n",
      "horse\r\n",
      "sheep\r\n",
      "cow\r\n",
      "elephant\r\n",
      "bear\r\n",
      "zebra\r\n",
      "giraffe\r\n",
      "backpack\r\n",
      "umbrella\r\n",
      "handbag\r\n",
      "tie\r\n",
      "suitcase\r\n",
      "frisbee\r\n",
      "skis\r\n",
      "snowboard\r\n",
      "sports ball\r\n",
      "kite\r\n",
      "baseball bat\r\n",
      "baseball glove\r\n",
      "skateboard\r\n",
      "surfboard\r\n",
      "tennis racket\r\n",
      "bottle\r\n",
      "wine glass\r\n",
      "cup\r\n",
      "fork\r\n",
      "knife\r\n",
      "spoon\r\n",
      "bowl\r\n",
      "banana\r\n",
      "apple\r\n",
      "sandwich\r\n",
      "orange\r\n",
      "broccoli\r\n",
      "carrot\r\n",
      "hot dog\r\n",
      "pizza\r\n",
      "donut\r\n",
      "cake\r\n",
      "chair\r\n",
      "sofa\r\n",
      "pottedplant\r\n",
      "bed\r\n",
      "diningtable\r\n",
      "toilet\r\n",
      "tvmonitor\r\n",
      "laptop\r\n",
      "mouse\r\n",
      "remote\r\n",
      "keyboard\r\n",
      "cell phone\r\n",
      "microwave\r\n",
      "oven\r\n",
      "toaster\r\n",
      "sink\r\n",
      "refrigerator\r\n",
      "book\r\n",
      "clock\r\n",
      "vase\r\n",
      "scissors\r\n",
      "teddy bear\r\n",
      "hair drier\r\n",
      "toothbrush\r\n"
     ]
    }
   ],
   "source": [
    "cat coco.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c18d72cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo():\n",
    "    \"\"\"Load yolo weight file\"\"\"\n",
    "    net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "    classes = []\n",
    "    with open(\"coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "#     classes = ['person'] # We only want to scan person in our video\n",
    "    layers_names = net.getLayerNames()\n",
    "    output_layers = [layers_names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "    return net, classes, colors, output_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b392cd4",
   "metadata": {},
   "source": [
    "### blobFromImage\n",
    "1.Mean subtraction  \n",
    "2.Scaling  \n",
    "3.And optionally channel swapping  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2909b7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_objects(img, net, outputLayers):\t\t\t\n",
    "    \"\"\"\n",
    "    Detect objects and normalize each pixel with a scaling factor of 0.00392\n",
    "    Assuming RGB instead of BGR\n",
    "    \"\"\"\n",
    "    blob = cv2.dnn.blobFromImage(img, scalefactor=0.00392, size=(320, 320), mean=(0, 0, 0), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outputs = net.forward(outputLayers)\n",
    "    return blob, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88e4ec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_dimensions(outputs, height, width):\n",
    "    \"\"\"\n",
    "    Creates a bounding box inside the image passed and return box dimensions and class id from cooc.names\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    confs = []\n",
    "    class_ids = []\n",
    "    for output in outputs:\n",
    "        for detect in output:\n",
    "            scores = detect[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            conf = scores[class_id]\n",
    "            if conf > 0.3:\n",
    "                center_x = int(detect[0] * width)\n",
    "                center_y = int(detect[1] * height)\n",
    "                w = int(detect[2] * width)\n",
    "                h = int(detect[3] * height)\n",
    "                x = int(center_x - w/2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confs.append(float(conf))\n",
    "                class_ids.append(class_id)\n",
    "    return boxes, confs, class_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17535ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_labels(boxes, confs, colors, class_ids, classes, img, out): \n",
    "    \"\"\"Draw labels with the box in out cv2 object (videostream)\"\"\"\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confs, 0.5, 0.4)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[class_ids[i]]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label, (x, y - 5), font, 1, color, 1)\n",
    "    out.write(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c3ab371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_video(video_path):\n",
    "    \"\"\"\n",
    "    Check whether a person exists in the video clip passed\n",
    "    video_path: param -> contains the video path of the file you downloaded\n",
    "    \"\"\"\n",
    "    is_person_flag = False\n",
    "    model, classes, colors, output_layers = load_yolo()\n",
    "    cap = cv2.VideoCapture(video_path) # Capture video\n",
    "    _, frame = cap.read()\n",
    "    height, width, channels = frame.shape\n",
    "#     print(frame.shape)\n",
    "#     cap.release()\n",
    "#     width = 640\n",
    "#     height = 360\n",
    "    \n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     codec = cv2.VideoWriter_fourcc(*'mp4v')    \n",
    "    codec = cv2.VideoWriter_fourcc(*'MJPG')\n",
    "    out = cv2.VideoWriter('/home/sahil/ISM_PROJECT/object-detection-yolo-opencv/output.avi', codec, 20.0, (width,height))\n",
    "    # save path of the video\n",
    "    while cap.isOpened():\n",
    "        # While video is open(until the end of the video)\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            print(frame.all())\n",
    "            break\n",
    "        height, width, channels = frame.shape\n",
    "        blob, outputs = detect_objects(frame, model, output_layers)\n",
    "        boxes, confs, class_ids = get_box_dimensions(outputs, height, width)\n",
    "        if 0 in class_ids:\n",
    "            # if a person exists in the video\n",
    "            is_person_flag = True\n",
    "        draw_labels(boxes, confs, colors, class_ids, classes, frame,out )\n",
    " \n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    if is_person_flag:\n",
    "        print('This was a person speaking video')\n",
    "    else:\n",
    "        print('Removing this video')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b062256",
   "metadata": {},
   "source": [
    "### Download youtube video from the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "424dee65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_video(video_path):\n",
    "    print(f'Downloading Youtube Video ')\n",
    "    video_path =  YouTube(video_path).streams.filter(progressive=True, file_extension='mp4').first().download()\n",
    "    print(f'Downloaded: {video_path}')\n",
    "    return video_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3119cac4",
   "metadata": {},
   "source": [
    "start_video('/home/sahil/ISM_PROJECT/object-detection-yolo-opencv/videos/pedestrians.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53d579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Youtube Video \n",
      "Downloaded: /home/sahil/ISM_PROJECT/object-detection-yolo-opencv/Great Speech by Narendra Modi in Lok Sabha.mp4\n",
      "Checking homo sapiens in the video...\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    video_link = \"https://www.youtube.com/watch?v=MRivVG0-GCg\"\n",
    "    video_path = download_video(video_link)\n",
    "    print('Checking homo sapiens in the video...')\n",
    "    start_video(video_path)\n",
    "    print('Done')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ccf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a7c4d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
